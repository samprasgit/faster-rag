# 词向量及向量知识库

## 一、词向量

### 1. 什么是词向量
![Embeddding](../figures/C3-1-embedding.png)
在机器学习和自然语言处理（NLP）中，词向量（Embeddings）是一种将非结构化数据，如单词、句子或者整个文档，转化为实数向量的技术。这些实数向量可以被计算机更好地理解和处理。

嵌入背后的主要想法是，相似或相关的对象在嵌入空间中的距离应该很近。
![similar](../figures/C3-2-similar.png)
举个例子，我们可以使用词嵌入（word embeddings）来表示文本数据。在词嵌入中，每个单词被转换为一个向量，这个向量捕获了这个单词的语义信息。例如，"king" 和 "queen" 这两个单词在嵌入空间中的位置将会非常接近，因为它们的含义相似。而 "apple" 和 "orange" 也会很接近，因为它们都是水果。而 "king" 和 "apple" 这两个单词在嵌入空间中的距离就会比较远，因为它们的含义不同。
### 2. 词向量的优势
在RAG（Retrieval Augmented Generation，检索增强生成）方面词向量的优势主要有两点：
* 词向量比文字更适合检索。当我们在数据库检索时，如果数据库存储的是文字，主要通过检索关键词（词法搜索）等方法找到相对匹配的数据，匹配的程度是取决于关键词的数量或者是否完全匹配查询句的；但是词向量中包含了原文本的语义信息，可以通过计算问题与数据库中数据的点积、余弦距离、欧几里得距离等指标，直接获取问题与数据在语义层面上的相似度；
* 词向量比其它媒介的综合信息能力更强，当传统数据库存储文字、声音、图像、视频等多种媒介时，很难去将上述多种媒介构建起关联与跨模态的查询方法；但是词向量却可以通过多种向量模型将多种数据映射成统一的向量形式。
### 3. 一般构建词向量的方法

在搭建 RAG 系统时，我们往往可以通过使用嵌入模型来构建词向量，我们可以选择：
* 使用各个公司的 Embedding API；
* 在本地使用嵌入模型将数据构建为词向量。

## 二、向量数据库

### 1. 什么是向量数据库
向量数据库是用于高效计算和管理大量向量数据的解决方案。向量数据库是一种专门用于存储和检索向量数据（embedding）的数据库系统。它与传统的基于关系模型的数据库不同，它主要关注的是向量数据的特性和相似性。

在向量数据库中，数据被表示为向量形式，每个向量代表一个数据项。这些向量可以是数字、文本、图像或其他类型的数据。向量数据库使用高效的索引和查询算法来加速向量数据的存储和检索过程。
### 2. 向量数据库的原理及核心优势
向量数据库中的数据以向量作为基本单位，对向量进行存储、处理及检索。向量数据库通过计算与目标向量的余弦距离、点积等获取与目标向量的相似度。当处理大量甚至海量的向量数据时，向量数据库索引和查询算法的效率明显高于传统数据库。
### 3. 主流的向量数据库

* [Chroma](https://www.trychroma.com/)：是一个轻量级向量数据库，拥有丰富的功能和简单的 API，具有简单、易用、轻量的优点，但功能相对简单且不支持GPU加速，适合初学者使用。
* [Weaviate](https://weaviate.io/)：是一个开源向量数据库。除了支持相似度搜索和最大边际相关性（MMR，Maximal Marginal Relevance）搜索外还可以支持结合多种搜索算法（基于词法搜索、向量搜索）的混合搜索，从而搜索提高结果的相关性和准确性。
* [Qdrant](https://qdrant.tech/)：Qdrant使用 Rust 语言开发，有极高的检索效率和RPS（Requests Per Second），支持本地运行、部署在本地服务器及Qdrant云三种部署模式。且可以通过为页面内容和元数据制定不同的键来复用数据。

### 4. 向量数据库的CRUD

#### 4.1 新增

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/82a893843f9e42448d9c356566e07cea~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2583&h=1299&s=224566&e=png&b=161f34)

LangChain的VectorStore类是一个通用的向量数据库的接口，它可以对接不同的底层向量数据库，如chroma、faiss、annoy等，实现统一的操作方法和API。VectorStore类还提供了一些高级的功能，如语义检索、最大边际相关性（MMR）等，可以帮助我们更好地利用向量数据库的能力。

要想向向量数据库中新增数据，我们首先需要创建一个VectorStore对象，并在创建时配置好embedding function，即用于将原始数据转换为向量的函数。如下所示：

```python
# 通过HuggingFace创建embedding_function
embeddings = HuggingFaceEmbeddings(model_name=model)
# 创建VectorStore的具体实现类Chroma对象，并指定collection_name和持久化目录
vector = Chroma(collection_name = 'cname', embedding_function=embeddings,persist_directory='/vs')

```

创建好VectorStore对象后，我们就可以使用`add_documents`方法来向向量数据库中插入数据了。`add_documents`方法接受doc对象的list作为参数，doc对象的`page_content`为要插入的文本内容，同时，我们还可以在doc对象中添加一些其他的元数据，用于后续的查询或过滤。例如，我们可以向向量数据库中插入以下doc对象：

```python 
# 先将文本拆分并转化为doc
loader = TextLoader(url,autodetect_encoding = True)

docs = loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = text_splitter.split_documents(docs)
# 插入向量数据库
vector.add_documents(documents=splits)

```

`add_documents`方法会返回一个id列表，这个id是doc的索引，用于唯一标识插入的doc对象。我们可以根据需要记录这个id，并与原始文件关联，一般来说，一个file对应多个doc，例如，我们可以将一个长文本拆分为多个段落，然后将每个段落作为一个doc插入到向量数据库中，这样可以提高检索的效率和精度。

#### 4.2 删除

要想从向量数据库中删除数据，我们可以使用delete方法，delete方法接受一个id或一个id列表作为参数，然后根据id来删除对应的doc对象。例如，我们可以使用以下代码来删除id为1的doc对象

```python 
# 删除id为1的doc对象
vector.delete('1')
```

如果我们不知道要删除的doc对象的id，但是知道它的一些元数据，我们可以先使用metadata中的字段来查询到id，然后再使用delete方法来批量删除。例如，我们可以使用以下代码来删除所有category为功能的doc对象：

```python
# 根据file_id的条件，查询到所有符合的doc对象的id
reuslt = vector.get(where={"file_id":file_id}) 
# 使用delete方法，批量删除这些id对应的doc对象
if reuslt['ids'] :
    vector.delete(reuslt['ids'])
```

#### 4.3 更新

VectorStore类没有提供专门的更新方法，因为更新一个doc对象相当于先删除它，然后再插入一个新的doc对象。因此，我们可以使用delete和insert方法来实现文档的更新。例如，我们可以使用以下代码来更新id为2的doc对象，将它的source从文档改为官网：

```python 
# 删除id为2的doc对象
vector.delete('2')

# 插入新的doc对象
vector.add_documents(new_doc)
```

#### 4.4 查询

![image-20240423093456507](/Users/samprasyuan/Library/Application Support/typora-user-images/image-20240423093456507.png)

VectorStore类提供了多种查询方法，用于根据不同的需求和场景来检索向量数据库中的数据。查询方法主要分为两种类型：similarity和mmr。

- similarity类型的查询方法是基于向量之间的相似度来进行检索的，它可以接受一个字符串或一个向量作为查询，然后返回最相似的doc对象以及相似度。

- mmr类型的查询方法是基于最大边际相关性（MMR）来进行检索的，它可以接受一个字符串或一个向量作为查询，然后返回一个多样化的doc对象列表，这些doc对象既与查询相关，又尽量不相似。

下面是四种查询方法使用方法:

- similarity_search：这个方法是最基本的相似度查询方法，它接受一个字符串作为查询，以及一个可选的`top_n`参数，用于指定返回的doc对象的数量，默认为4，然后返回最相似的doc对象或它们的id。例如，我们可以使用以下代码来查询与“语义检索”最相似的doc对象：

  ```python
  # 查询与“语义检索”最相似的doc对象
  docs = vector.similarity_search("语义检索")
  
  # 打印查询结果
  for doc in docs:
      print(doc)
  ```

- similarity_search_with_score：这个方法与similarity_search类似，但是它会同时返回向量之间的距离，距离越小表示越相似。例如，我们可以使用以下代码来查询与“语义检索”最相似的doc对象，并打印它们的分数：

```pyhton 
# 查询与“语义检索”最相似的doc对象，并返回分数
docs_with_score = vector.similarity_search_with_score("语义检索")

# 打印查询结果和分数
for doc_with_score in docs_with_score:
    print(doc_with_score[0], doc_with_score[1])
```

- similarity_search_with_relevance_scores：这个方法与similarity_search_with_score类似，但是它会将分数转换为一个介于0和1之间的相关度评分，这个评分表示查询和doc对象之间的语义相关程度，评分越高越相似。代码与similarity_search_with_score类似，不再额外示例

- max_marginal_relevance_search：这个方法是基于最大边际相关性（MMR）来进行查询的，最大边际相关性（MMR）是一种用于检索或摘要的方法，它既考虑了查询和文档之间的相似度，又考虑了文档之间的多样性，从而避免返回重复或冗余的结果。它接受一个字符串或一个向量作为查询，以及一个可选的top_n参数，用于指定返回的doc对象的数量，默认为10，然后返回一个多样化的doc对象列表，这些doc对象既与查询相关，又尽量不相似。这个方法可以用于生成摘要、提取关键信息、避免重复内容等场景。例如，我们可以使用以下代码来查询与“LangChain”相关的但不相似的doc对象：

  ```python
  # 查询与“LangChain”相关的但不相似的doc对象
  docs = vector.max_marginal_relevance_search("LangChain")
  
  # 打印查询结果
  for doc in docs:
      print(doc)
  ```

  

## 参考

https://juejin.cn/post/7326978130601230374



